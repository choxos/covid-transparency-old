---
title: "Transparency indicators across the dentistry and oral health literature"
author: Ahmad Sofi-Mahmudi, Eero Raittio, Sergio E Uribe
date: "1/8/2022"
output: html_document
---

# Loading required packages

```{r}
pacman::p_load(dplyr,
               rtransparent, 
               metareadr, 
               europepmc)
```


# Load the datasets

## Load all open access dentistry and oral health papers indexed in PubMed to the end of 2021:

```{r}
COVID_19_keywords <- read.csv("covid_keywords.csv")
```

```{r}
COVID_19_keywords <- COVID_19_keywords %>% mutate(
  search.term.title = paste0("TITLE:", '"', Keyword, '"'),
  search.term.keyword = paste0("KW:", '"', Keyword, '"'),
  search.term.results = paste0("RESULTS:", '"', Keyword, '"'))

TitleQuery <- paste(COVID_19_keywords$search.term.title,
                     collapse = " OR ")

KeywordQuery <- paste(COVID_19_keywords$search.term.keyword,
                     collapse = " OR ")

ResultQuery <- paste(COVID_19_keywords$search.term.results,
                     collapse = " OR ")
```

## Load all open-access and EPMC COVID-19-related papers indexed in PubMed

As in this step we should download a large file that includes the characteristics of papers of our query, to ease the process, we divided our query to five separate queries based on the date:
1- first half of 2020;
2- second half of 2020;
3- first half of 2021;
4- second half of 2021;
5- the first two months of 2022.

```{r}

db_2020_1 <- epmc_search(query = paste0("(", TitleQuery, " OR ", KeywordQuery, " OR ", ResultQuery, ") ", 'AND (SRC:"MED") AND (LANG:"eng" OR LANG:"en" OR LANG:"us") AND (FIRST_PDATE:[2020-01-01 TO 2020-06-30]) AND (OPEN_ACCESS:y) AND (PUB_TYPE:"Journal Article" OR PUB_TYPE:"research-article" OR PUB_TYPE:"rapid-communication" OR PUB_TYPE:"product-review")'), limit = 100000, output = "parsed")

total oa and non oa: 19467

db_2020_2 <- epmc_search(query = paste0("(", TitleQuery, " OR ", KeywordQuery, " OR ", ResultQuery, ") ", 'AND (SRC:"MED") AND (LANG:"eng" OR LANG:"en" OR LANG:"us") AND (FIRST_PDATE:[2020-07-01 TO 2020-12-31]) AND (OPEN_ACCESS:y) AND (PUB_TYPE:"Journal Article" OR PUB_TYPE:"research-article" OR PUB_TYPE:"rapid-communication" OR PUB_TYPE:"product-review")'), limit = 100000, output = "parsed")

total oa and non oa: 43107

db_2021_1 <- epmc_search(query = paste0("(", TitleQuery, " OR ", KeywordQuery, " OR ", ResultQuery, ") ", 'AND (SRC:"MED") AND (LANG:"eng" OR LANG:"en" OR LANG:"us") AND (FIRST_PDATE:[2021-01-01 TO 2021-06-30]) AND (OPEN_ACCESS:y) AND (PUB_TYPE:"Journal Article" OR PUB_TYPE:"research-article" OR PUB_TYPE:"rapid-communication" OR PUB_TYPE:"product-review")'), limit = 100000, output = "parsed")

total oa and non oa: 50512

db_2021_2 <- epmc_search(query = paste0("(", TitleQuery, " OR ", KeywordQuery, " OR ", ResultQuery, ") ", 'AND (SRC:"MED") AND (LANG:"eng" OR LANG:"en" OR LANG:"us") AND (FIRST_PDATE:[2021-07-01 TO 2021-12-31]) AND (OPEN_ACCESS:y) AND (PUB_TYPE:"Journal Article" OR PUB_TYPE:"research-article" OR PUB_TYPE:"rapid-communication" OR PUB_TYPE:"product-review")'), limit = 100000, output = "parsed")

total oa and non oa: 47975

db_2022 <- epmc_search(query = paste0("(", TitleQuery, " OR ", KeywordQuery, " OR ", ResultQuery, ") ", 'AND (SRC:"MED") AND (LANG:"eng" OR LANG:"en" OR LANG:"us") AND (FIRST_PDATE:[2022-01-01 TO 2022-02-28]) AND (OPEN_ACCESS:y) AND (PUB_TYPE:"Journal Article" OR PUB_TYPE:"research-article" OR PUB_TYPE:"rapid-communication" OR PUB_TYPE:"product-review")'), limit = 100000, output = "parsed")

total oa and non oa: 14272

```

## We then do the following for each of them

Let's see how many duplicates are there:
```{r}
table(duplicated(db_2020_1$pmid))
table(duplicated(db_2020_2$pmid))
table(duplicated(db_2021_1$pmid))
table(duplicated(db_2021_2$pmid))
table(duplicated(db_2022$pmid))

```

Removing the duplicates:
```{r}
db_2020_1 <- db_2020_1 %>% distinct(pmid, .keep_all = TRUE)
db_2020_2 <- db_2020_2 %>% distinct(pmid, .keep_all = TRUE)
db_2021_1 <- db_2021_1 %>% distinct(pmid, .keep_all = TRUE)
db_2021_2 <- db_2021_2 %>% distinct(pmid, .keep_all = TRUE)
db_2022 <- db_2022 %>% distinct(pmid, .keep_all = TRUE)

```


Creating a new column from pmcid column and removing "PMC" from the cells:
```{r}
db_2020_1$pmcid_ <- gsub("PMC", "", as.character(db_2020_1$pmcid))
db_2020_2$pmcid_ <- gsub("PMC", "", as.character(db_2020_2$pmcid))
db_2021_1$pmcid_ <- gsub("PMC", "", as.character(db_2021_1$pmcid))
db_2021_2$pmcid_ <- gsub("PMC", "", as.character(db_2021_2$pmcid))
db_2022$pmcid_ <- gsub("PMC", "", as.character(db_2022$pmcid))

```

Now, we make five folders for xml format articles:
```{r}
dir.create(c("pmc_2020_1", "pmc_2020_2", "pmc_2021_1", "pmc_2021_2", "pmc_2022"))
```

Next, we download xmls in format accessible with metareadr To skip errors (i.e., The metadata format 'pmc' is not supported by the item or by the repository.), first define a new function:

```{r}
skipping_errors <- function(x) tryCatch(mt_read_pmcoa(x), error = function(e) e)
```

Next, we download xmls in format accessible with rtransparent:
```{r}
setwd("pmc_2020_1")
sapply(db_2020_1$pmcid_, skipping_errors)

setwd("../pmc_2020_2")
sapply(db_2020_2$pmcid_, skipping_errors)

setwd("../pmc_2021_1")
sapply(db_2021_1$pmcid_, skipping_errors)

setwd("../pmc_2021_2")
sapply(db_2021_2$pmcid_, skipping_errors)

setwd("../pmc_2022")
sapply(db_2022$pmcid_, skipping_errors)

```
Error in 8013644 - The metadata format 'pmc' is not supported by the item or by the repository.

Error in 7572235 - The value of the identifier argument is unknown or illegal in this repository.

Now we run rtransparent:
```{r}
filepath = dir(pattern=glob2rx("PMC*.xml"))

results_table_all <- sapply(filepath, rt_all_pmc)

results_table_data <- rt_data_code_pmc_list(
  filepath,
  remove_ns=F,
  specificity = "low")

write.csv(rt_data_code_pmc_list(filepath, remove_ns=F, specificity = "low"), "rt_data.csv")

f1_data <- rt_data_code_pmc_list(f1, remove_ns=F, specificity = "low")

```

A list is created now. We should convert this list to a dataframe:
```{r}
df1 <- data.table::rbindlist(results_table_all_f1, fill = TRUE)
df2 <- data.table::rbindlist(results_table_all_f2, fill = TRUE)
df3 <- data.table::rbindlist(results_table_all_f3, fill = TRUE)
df4 <- data.table::rbindlist(results_table_all_f4, fill = TRUE)
df5 <- data.table::rbindlist(results_table_all_f5, fill = TRUE)

```


Merge data sharing results to database file:

```{r}
setwd('..')
db <- db[!duplicated(db[, 4]),]
opendata <- merge(db, results_table_data, by = "pmid") %>% merge(df)
```

Random sample of search results for validation of our approach (100 refs):
```{r}
set.seed(100)

randomsample3 <- db3[sample(nrow(db3), 100), ]
```


